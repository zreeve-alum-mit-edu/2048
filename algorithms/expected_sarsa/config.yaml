# Expected SARSA Algorithm Configuration
# Milestone 20: Expected SARSA with one-hot representation and merge_reward
#
# Expected SARSA uses the expected Q-value under the policy for
# bootstrapping, reducing variance compared to SARSA.

# Training parameters
training:
  total_steps: 100000           # Total training steps
  learning_rate: 0.0005         # Adam learning rate
  gamma: 0.99                   # Discount factor

# Epsilon schedule (per DEC-0035 pattern)
epsilon:
  start: 1.0                    # Initial epsilon
  end: 0.01                     # Final epsilon
  decay_steps: 100000           # Steps to decay from start to end

# Network architecture
network:
  hidden_layers: [256, 256]     # Hidden layer sizes
  activation: relu              # Activation function

# Environment
env:
  n_games: 32                   # Number of parallel games

# Checkpointing
checkpoint:
  save_frequency: 10000         # Save checkpoint every N steps
  save_dir: checkpoints/expected_sarsa  # Directory for checkpoints

# Logging
logging:
  log_frequency: 1000           # Log metrics every N steps
  eval_frequency: 10000         # Evaluate every N steps
  eval_games: 100               # Number of games for evaluation
