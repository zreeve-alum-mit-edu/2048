# REINFORCE Algorithm Configuration
# Milestone 7: Vanilla policy gradient with one-hot representation and merge_reward
#
# REINFORCE is the simplest policy gradient algorithm - uses Monte Carlo returns
# to update the policy. No baseline/critic for variance reduction.

# Training parameters
training:
  total_steps: 100000           # Total training steps
  learning_rate: 0.0001         # Adam learning rate
  gamma: 0.99                   # Discount factor
  update_frequency: 32          # Steps between policy updates (batch of episodes)

# Network architecture
network:
  hidden_layers: [256, 256]     # Hidden layer sizes
  activation: relu              # Activation function

# Environment
env:
  n_games: 32                   # Number of parallel games

# Checkpointing
checkpoint:
  save_frequency: 10000         # Save checkpoint every N steps
  save_dir: checkpoints/reinforce  # Directory for checkpoints

# Logging
logging:
  log_frequency: 1000           # Log metrics every N steps
  eval_frequency: 10000         # Evaluate every N steps
  eval_games: 100               # Number of games for evaluation
